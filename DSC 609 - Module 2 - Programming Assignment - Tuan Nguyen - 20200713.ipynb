{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tuan Nguyen - DSC609 Module 2 - July 13, 2020\n",
    "### Perform Ridge Regression AND Lasso on the data of your own choosing.\n",
    "### Compare AND contrast the results of Ridge and Lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "### Framework > Library > Package > Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Data and Set Variables\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\cg\\Desktop\\Echo\\School\\DSC607\\Week 2\\diabetes.csv')\n",
    "x = df[['BloodPressure','BMI', 'Age']].values\n",
    "y = df[['Outcome']].values\n",
    "\n",
    "### For the outcome variable, 0 is No and 1 is Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Outcome   R-squared:                       0.143\n",
      "Model:                            OLS   Adj. R-squared:                  0.140\n",
      "Method:                 Least Squares   F-statistic:                     42.57\n",
      "Date:                Wed, 15 Jul 2020   Prob (F-statistic):           1.92e-25\n",
      "Time:                        12:41:31   Log-Likelihood:                -461.31\n",
      "No. Observations:                 768   AIC:                             930.6\n",
      "Df Residuals:                     764   BIC:                             949.2\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        -0.4396      0.085     -5.161      0.000      -0.607      -0.272\n",
      "BloodPressure    -0.0020      0.001     -2.234      0.026      -0.004      -0.000\n",
      "BMI               0.0185      0.002      8.774      0.000       0.014       0.023\n",
      "Age               0.0100      0.001      7.142      0.000       0.007       0.013\n",
      "==============================================================================\n",
      "Omnibus:                      731.837   Durbin-Watson:                   1.939\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               74.368\n",
      "Skew:                           0.448   Prob(JB):                     7.10e-17\n",
      "Kurtosis:                       1.767   Cond. No.                         455.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "### Linear Regression\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "linear = smf.ols('Outcome ~ BloodPressure + BMI + Age', data = df).fit()\n",
    "print(linear.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([1.00000000e+10, 7.56463328e+09, 5.72236766e+09, 4.32876128e+09,\n",
       "       3.27454916e+09, 2.47707636e+09, 1.87381742e+09, 1.41747416e+09,\n",
       "       1.07226722e+09, 8.11130831e+08, 6.13590727e+08, 4.64158883e+08,\n",
       "       3.51119173e+08, 2.65608778e+08, 2.00923300e+08, 1.51991108e+08,\n",
       "       1.14975700e+08, 8.69749003e+07, 6.57933225e+07, 4.97702356e+07,\n",
       "       3.76493581e+07, 2.84803587e+0...\n",
       "       2.00923300e+00, 1.51991108e+00, 1.14975700e+00, 8.69749003e-01,\n",
       "       6.57933225e-01, 4.97702356e-01, 3.76493581e-01, 2.84803587e-01,\n",
       "       2.15443469e-01, 1.62975083e-01, 1.23284674e-01, 9.32603347e-02,\n",
       "       7.05480231e-02, 5.33669923e-02, 4.03701726e-02, 3.05385551e-02,\n",
       "       2.31012970e-02, 1.74752840e-02, 1.32194115e-02, 1.00000000e-02]),\n",
       "        cv=None, fit_intercept=True, gcv_mode=None, normalize=True,\n",
       "        scoring=None, store_cv_values=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Ridge Regression\n",
    "lambdas = 10**np.linspace(10,-2,100)\n",
    "ridge = RidgeCV(alphas = lambdas, normalize = True)\n",
    "ridge.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02310129700083158"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find the best Tuning Parameter (Lambda, or the Ridge Regression Penalty) of the Ridge Regression with:\n",
    "ridge.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0018405 ,  0.01803721,  0.00972941]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find the coefficients of the Ridge Regression with:\n",
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42432393])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find the Intercept of the Ridge Regression with:\n",
    "ridge.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=array([1.00000000e+10, 7.56463328e+09, 5.72236766e+09, 4.32876128e+09,\n",
       "       3.27454916e+09, 2.47707636e+09, 1.87381742e+09, 1.41747416e+09,\n",
       "       1.07226722e+09, 8.11130831e+08, 6.13590727e+08, 4.64158883e+08,\n",
       "       3.51119173e+08, 2.65608778e+08, 2.00923300e+08, 1.51991108e+08,\n",
       "       1.14975700e+08, 8.69749003e+07, 6.57933225e+07, 4.97702356e+07,\n",
       "       3.76493581e+07, 2.84803587e+0...\n",
       "       2.15443469e-01, 1.62975083e-01, 1.23284674e-01, 9.32603347e-02,\n",
       "       7.05480231e-02, 5.33669923e-02, 4.03701726e-02, 3.05385551e-02,\n",
       "       2.31012970e-02, 1.74752840e-02, 1.32194115e-02, 1.00000000e-02]),\n",
       "        copy_X=True, cv=None, eps=0.001, fit_intercept=True, max_iter=1000,\n",
       "        n_alphas=100, n_jobs=None, normalize=True, positive=False,\n",
       "        precompute='auto', random_state=None, selection='cyclic', tol=0.0001,\n",
       "        verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Lasso Regression\n",
    "lambdas = 10**np.linspace(10,-2,100)\n",
    "lasso = LassoCV(alphas = lambdas, normalize = True)\n",
    "lasso.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000000.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find the best Tuning Parameter (Lambda, or the Lasso Regression Penalty) of the Ridge Regression with:\n",
    "lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find the coefficients of the Lasso Regression with:\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3489583333333333"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find the Intercept of the Lasso Regression with:\n",
    "lasso.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ridge vs. Lasso Regression\n",
    "\n",
    "### like linear regression, both ridge and lasso regressions are linear models that make predictions using a linear function with input variables.\n",
    "### Both models are similar in that they both introduce some bias into linear models so there can be a decrease in variance when applying the model to test data.\n",
    "### The formula for both models start with taking the sum of squared residuals then applying a penalty to the sum of squared residuals.\n",
    "\n",
    "### For Ridge (L2) Regression, the penalty/alpha/tuning parameter is (Lambda + The Slope Squared). \n",
    "### For Lasso (L1) Regression, the penalty/alpha/tuning parameter is (Lambda + The Absolute Value of the Slope)\n",
    "### For both regressions, the value of lambda is arbitary and determines the severity of the penalty.\n",
    "### The main difference between ridge and lasso regression is that while ridge regression can only shrink the slope asymptotically close to zero, lasso regression can shrink the slope all the way to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare and Contrast the results of the Models\n",
    "\n",
    "### Lambda can be any number from zero to infinity, and as lambda increases, the slope of the line will get smaller and smaller. \n",
    "### The Lambda for the ridge regression was 0.02310129700083158 while the Lambda for the lasso regression was a very high 10000000000.0\n",
    "### With the ridge regression, we see the coefficients come out to -0.0018405 ,  0.01803721, and 0.00972941.\n",
    "### Meanwhile, we see the coefficients for the lasso regression all came out to zero.\n",
    "### This may seem strange but since the lambda for lasso regression is extremly high, it makes sense that all the coefficients(and therefore the slope) is at zero.\n",
    "### In speaking with the professor and rewatching this week's lecture, it became clear both ridge and lasso regressions are best used when the number of features (m) is much greater than the number of inputs (n) in our data.\n",
    "### Since the number of features (m) was not greater than the number of inputs (n) in our data, then the results can become difficult to interpret.\n",
    "\n",
    "### Another notable difference between the models is in the intercepts. The y-intercept for the ridge regression starts at -0.42432393 while the y-intercept for lasso regression starts a bit higher at 0.3489583333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
